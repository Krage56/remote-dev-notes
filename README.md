# Intro
В этом файле я отмечаю основные этапы, необходимые для того, чтобы запуститься по ssh на удалённой машине (виртуальной, с GPU), создать на ней докер-образ и с его помощью запустить некоторую нейронку, которая может использовать GPU.

# Получаем доступ к удалённой машине
0. Настройка ssh сервера, добавляем публичный ключ (`id_rsa.pub`) машины, с которой планируется иметь доступ, на удалённую.
1. Подключаемся командой:
```
ssh -i ./id_rsa <user>@<ip>
```

# Проверка пререквизитов
На удалённой машине нам необходимы две компоненты: `docker` и драйвера `nvidia`.

Описывать установку докера здесь не буду, наличие драйверов `nvidia` проверяется командой `nvidia-smi`. Если вывод примерно такой:
```
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.104.12             Driver Version: 535.104.12   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:05.0 Off |                    0 |
| N/A   27C    P0              50W / 400W |      4MiB / 40960MiB |     27%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
```
то всё в порядке, можем продолжать. 

Если такого вывода нет, или сам пакет `nvidia-smi` отсутствует, нужно пройти по шагам, которые описаны по [ссылке](https://docs.nvidia.com/cuda/cuda-quick-start-guide/index.html#linux). 

# Настройка Docker
Редактируем файл `/etc/docker/daemon.json` (прописываем в него путь до бинаря с контейнер-рантаймом):

```
{
    "runtimes": {
        "nvidia": {
            "path": "/usr/bin/nvidia-container-runtime",
            "runtimeArgs": []
         }
    },
    "default-runtime": "nvidia"
}
```
Затем перезапускаем Docker командой
`sudo systemctl restart docker`
и продолжаем.

# Когда драйвера установлены и докер настроен
Выбираем один из докер-файлов в репозитории и редактируем его под себя:
- Файл [cuda](./Dockerfile_cuda) собран на основе образа с `cuda` и может быть спокойно использован для работы с другими библиотеками (меняем внутри `pytorch` на интересующий нас пакет).
- Файл [torch](./Dockerfile_torch) собран на основе образа `pytorch` и может быть использован только для проектов на `pytorch`.

Когда появился нужны докерфайл, переименовываем его `Dockerfile_xxx` -> `Dockerfile` и запускаем Docker-compose командой `sudo docker-compose up -d --build`.

Если сборка прошла успешно, запускаем контейнер:
```
sudo docker run torch21_worker --name '<container_name>' --runtime=nvidia --gpus all
```

# Если понадобилась Anaconda
## Если нужно использовать окружение Anaconda при сборке
Команда, чтобы все последующие `RUN` вызовы проходили в среде Anaconda.
```
RUN conda create --name myenv
SHELL ["conda", "run", "-n", "myenv", "/bin/bash", "-c"]
```

## Если нужно просто запуститься с доступом к GPU
```
RUN conda create --name myenv

ENTRYPOINT ["conda", "run", "-n", "myenv", "python3", "entrypoint.py"]
```


# Если нужно посмотреть выхлоп контейнера
```
RUN wget https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py
python collect_env.py
```